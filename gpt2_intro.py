# -*- coding: utf-8 -*-
"""gpt2_intro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j2WYpHt5M_-ztYSNjCT2MEtJbSsQerCs

# This is the Jupyter Notebook ran in Google Colab during the GPT-2 Workshop at the Data Science Minneapolis Event on January 25th, 2020.

We need to pip install the gpt-2-simple Python library. This is a wrapper around the source code that OpenAI published via GitHub.
"""

!pip install -q gpt-2-simple

"""Now that we've pip installed the library, we can import it into the Python Notebook."""

import gpt_2_simple as gpt2

"""Here we can decide which model size we want to download and use, 1558M is the largest model, 774M is the second largest. The larger the model, the longer it takes to run the inference and download/load."""

model_size = "1558M"

"""We need to download the model to the file storage system."""

gpt2.download_gpt2(model_name=model_size)

"""Now we need to start the Tensorflow session to allow us to run the Tensorflow model."""

sess = gpt2.start_tf_sess()

"""With the model downloaded and stored in the local file storage, we can load the model into memory to use."""

gpt2.load_gpt2(sess, model_name = model_size)

"""Here we can send the text we want the model to continue off of. This will be sent into the prefix parameter of the `generate()` function."""

text = "Data Science Minneapolis is ecstatic from the generous contributions from Google Colab's department"

"""`generate()` is the function we use to generate the text. We need to pass the Tensorflow session, model we selected, and the text we want to continue off of to the `prefix` parameter."""

gpt2.generate(
    sess,
    model_name = model_size,
    prefix = text,
    length = 100,
    temperature = 0.7,
    top_p = 0.9,
    nsamples = 1,
    batch_size = 1
)